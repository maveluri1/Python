{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ...,  0.20401277,\n",
       "         0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.68442195,\n",
       "        -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, ..., -1.10325546,\n",
       "         0.60439732, -0.10558415],\n",
       "       ...,\n",
       "       [ 0.3429808 ,  0.00330087,  0.14964075, ..., -0.73518964,\n",
       "        -0.68519336, -0.27575966],\n",
       "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.24020459,\n",
       "        -0.37110101,  1.17073215],\n",
       "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.20212881,\n",
       "        -0.47378505, -0.87137393]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means Clusering\n",
    "# 30 Nov 2019\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "diabetes_df.drop(columns='Outcome',inplace=True)  #dropping output variable from the dataset. Seting the inplace parameter to True so that drop happens immediately\n",
    "\n",
    "# Splitting the data in to 80 : 20 ratio for traning and test purpose, \"random\" is used to freeze the data\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(diabetes_df,y,test_size=0.20,random_state=31)  # to not change the random model \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler_df = scaler.fit_transform(diabetes_df)\n",
    "\n",
    "scaler_df\n",
    "\n",
    "# get the list of all continuous columns and put through the loop\n",
    "\n",
    "#for col in diabetes_df.columns: \n",
    "#    X_train[col]=standard_scaler.fit_transform(np.array(X_train[col]).reshape(-1,1))\n",
    "#    X_test[col]=standard_scaler.transform(np.array(X_test[col]).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb186e8240>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "no_of_clusters =[1,2,3,4,5,6,7,8]\n",
    "wss=[]\n",
    "\n",
    "for k in no_of_clusters:\n",
    "    k_means=KMeans(n_clusters=k, random_state=32)\n",
    "    k_means.fit_predict(scaler_df)\n",
    "    wss.append(k_means.inertia_)\n",
    "    \n",
    "plt.plot(no_of_clusters,wss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_new="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3, 4, 0, 4, 4, 2, 1, 3, 4, 3, 3, 1, 3, 2, 0, 4, 0, 0, 0, 3,\n",
       "       3, 3, 3, 3, 3, 4, 3, 3, 3, 1, 4, 4, 3, 0, 3, 3, 0, 1, 0, 3, 3, 1,\n",
       "       3, 0, 4, 4, 0, 2, 4, 4, 4, 1, 1, 4, 1, 0, 0, 0, 2, 3, 4, 0, 3, 4,\n",
       "       0, 3, 4, 4, 0, 0, 3, 1, 4, 4, 3, 0, 2, 4, 4, 2, 3, 4, 3, 0, 3, 0,\n",
       "       3, 4, 4, 0, 0, 3, 4, 1, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 4, 0,\n",
       "       0, 1, 4, 4, 1, 3, 3, 4, 4, 4, 0, 0, 0, 3, 4, 0, 0, 0, 0, 3, 1, 3,\n",
       "       1, 3, 4, 4, 4, 4, 4, 1, 3, 0, 4, 3, 1, 4, 3, 0, 3, 4, 0, 4, 1, 1,\n",
       "       3, 0, 4, 4, 4, 3, 0, 3, 0, 4, 4, 3, 4, 4, 4, 4, 3, 0, 2, 0, 4, 1,\n",
       "       3, 0, 3, 3, 4, 0, 4, 4, 3, 3, 1, 0, 0, 0, 4, 3, 3, 2, 3, 1, 4, 4,\n",
       "       0, 1, 4, 4, 4, 4, 3, 4, 1, 3, 4, 3, 4, 0, 3, 0, 3, 1, 0, 0, 0, 3,\n",
       "       1, 3, 2, 3, 4, 4, 4, 0, 1, 0, 0, 1, 4, 4, 4, 3, 1, 0, 3, 4, 4, 0,\n",
       "       4, 0, 0, 3, 3, 1, 1, 4, 3, 4, 4, 0, 3, 0, 0, 4, 1, 3, 1, 2, 0, 3,\n",
       "       4, 3, 2, 0, 4, 2, 0, 4, 4, 0, 3, 0, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3,\n",
       "       1, 0, 4, 0, 0, 0, 0, 0, 3, 0, 1, 0, 3, 3, 2, 0, 0, 3, 4, 0, 3, 4,\n",
       "       0, 0, 4, 0, 4, 4, 3, 4, 4, 4, 0, 3, 4, 4, 4, 3, 0, 4, 0, 3, 0, 3,\n",
       "       3, 4, 2, 3, 4, 1, 2, 3, 1, 3, 4, 4, 4, 3, 3, 3, 4, 2, 4, 0, 4, 4,\n",
       "       4, 4, 4, 3, 0, 2, 3, 1, 1, 3, 3, 3, 1, 0, 4, 4, 4, 0, 1, 4, 0, 0,\n",
       "       0, 1, 4, 0, 3, 0, 0, 4, 4, 4, 4, 4, 0, 3, 1, 0, 0, 3, 1, 4, 3, 1,\n",
       "       0, 0, 4, 0, 4, 3, 0, 3, 3, 0, 3, 4, 3, 1, 0, 0, 1, 4, 0, 1, 4, 0,\n",
       "       4, 4, 0, 4, 0, 4, 1, 1, 2, 1, 0, 0, 2, 4, 4, 4, 4, 2, 3, 4, 4, 3,\n",
       "       0, 4, 0, 3, 4, 0, 4, 0, 0, 4, 4, 4, 0, 2, 0, 3, 3, 4, 1, 3, 3, 4,\n",
       "       0, 4, 3, 4, 4, 0, 2, 0, 0, 0, 0, 3, 4, 3, 0, 4, 3, 3, 1, 0, 4, 0,\n",
       "       2, 0, 1, 1, 4, 3, 0, 0, 0, 3, 2, 3, 4, 4, 3, 1, 4, 0, 0, 3, 0, 3,\n",
       "       0, 0, 4, 3, 3, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 0, 2, 3, 4, 4, 4, 4,\n",
       "       0, 4, 4, 0, 0, 2, 0, 2, 4, 3, 0, 0, 1, 0, 3, 0, 0, 1, 1, 4, 0, 3,\n",
       "       4, 0, 3, 4, 0, 1, 0, 3, 3, 3, 3, 1, 0, 4, 4, 4, 0, 3, 0, 0, 4, 4,\n",
       "       4, 4, 1, 0, 4, 0, 3, 1, 0, 4, 3, 3, 1, 4, 3, 4, 1, 2, 3, 0, 3, 0,\n",
       "       1, 1, 4, 2, 3, 4, 4, 2, 4, 3, 2, 0, 1, 4, 1, 4, 4, 1, 1, 0, 3, 4,\n",
       "       3, 4, 3, 2, 0, 0, 3, 0, 4, 0, 4, 4, 3, 4, 3, 0, 4, 4, 3, 3, 3, 4,\n",
       "       0, 4, 4, 4, 3, 2, 0, 1, 4, 0, 3, 4, 4, 0, 0, 4, 0, 1, 4, 0, 3, 0,\n",
       "       3, 0, 1, 1, 0, 0, 3, 3, 0, 3, 1, 4, 3, 0, 3, 3, 3, 4, 4, 4, 4, 0,\n",
       "       0, 4, 3, 0, 4, 4, 0, 0, 3, 3, 0, 0, 4, 1, 4, 2, 0, 0, 0, 3, 3, 2,\n",
       "       4, 0, 2, 1, 3, 0, 1, 3, 3, 4, 4, 1, 1, 3, 0, 3, 4, 0, 0, 0, 3, 0,\n",
       "       0, 0, 4, 4, 4, 4, 0, 4, 3, 0, 0, 3, 0, 4, 3, 4, 4, 3, 1, 3, 0, 0,\n",
       "       1, 3, 4, 0, 4, 1, 3, 0, 3, 3, 4, 3, 4, 3, 4, 3, 0, 4, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the above graph we consider 5 or 6 as minimum \n",
    "# now create a model with k =5\n",
    "# Ineria is sum of squared errors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k_means_1=KMeans(n_clusters=5,random_state=42)\n",
    "k_means_1.fit_predict(scaler_df)\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.562476</td>\n",
       "      <td>3.056871</td>\n",
       "      <td>4.858964</td>\n",
       "      <td>1.738996</td>\n",
       "      <td>3.243453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.062636</td>\n",
       "      <td>4.098660</td>\n",
       "      <td>3.985635</td>\n",
       "      <td>3.073679</td>\n",
       "      <td>1.328311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.996071</td>\n",
       "      <td>4.051160</td>\n",
       "      <td>4.191577</td>\n",
       "      <td>2.711857</td>\n",
       "      <td>3.345838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.155004</td>\n",
       "      <td>3.878796</td>\n",
       "      <td>4.042752</td>\n",
       "      <td>3.491955</td>\n",
       "      <td>1.223825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.630604</td>\n",
       "      <td>5.795903</td>\n",
       "      <td>7.047969</td>\n",
       "      <td>6.830491</td>\n",
       "      <td>6.659752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.049418</td>\n",
       "      <td>4.183152</td>\n",
       "      <td>3.861658</td>\n",
       "      <td>2.170804</td>\n",
       "      <td>1.490791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.121420</td>\n",
       "      <td>3.854006</td>\n",
       "      <td>3.593685</td>\n",
       "      <td>3.419456</td>\n",
       "      <td>1.847884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.142601</td>\n",
       "      <td>5.815561</td>\n",
       "      <td>2.403344</td>\n",
       "      <td>4.597557</td>\n",
       "      <td>4.483896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.366437</td>\n",
       "      <td>3.263081</td>\n",
       "      <td>7.302549</td>\n",
       "      <td>5.690635</td>\n",
       "      <td>6.091053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.147373</td>\n",
       "      <td>6.307833</td>\n",
       "      <td>6.407599</td>\n",
       "      <td>4.340649</td>\n",
       "      <td>4.922305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.800901</td>\n",
       "      <td>4.170461</td>\n",
       "      <td>5.000682</td>\n",
       "      <td>2.410370</td>\n",
       "      <td>2.223356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.663134</td>\n",
       "      <td>3.845279</td>\n",
       "      <td>4.826079</td>\n",
       "      <td>2.156993</td>\n",
       "      <td>3.583853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.070799</td>\n",
       "      <td>5.062746</td>\n",
       "      <td>6.010195</td>\n",
       "      <td>3.402221</td>\n",
       "      <td>5.019032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.535633</td>\n",
       "      <td>5.351579</td>\n",
       "      <td>8.767884</td>\n",
       "      <td>7.747371</td>\n",
       "      <td>8.028075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.208017</td>\n",
       "      <td>2.354485</td>\n",
       "      <td>4.792187</td>\n",
       "      <td>2.151853</td>\n",
       "      <td>3.299707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.749667</td>\n",
       "      <td>5.623622</td>\n",
       "      <td>1.314599</td>\n",
       "      <td>4.419648</td>\n",
       "      <td>3.945181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.028604</td>\n",
       "      <td>2.657881</td>\n",
       "      <td>6.189050</td>\n",
       "      <td>4.221002</td>\n",
       "      <td>3.797792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.034162</td>\n",
       "      <td>4.167379</td>\n",
       "      <td>3.993609</td>\n",
       "      <td>1.874972</td>\n",
       "      <td>1.846403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.712309</td>\n",
       "      <td>4.062378</td>\n",
       "      <td>3.752548</td>\n",
       "      <td>4.162374</td>\n",
       "      <td>3.345230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.648980</td>\n",
       "      <td>2.679707</td>\n",
       "      <td>4.317503</td>\n",
       "      <td>2.709044</td>\n",
       "      <td>1.700699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.658737</td>\n",
       "      <td>1.889505</td>\n",
       "      <td>5.876538</td>\n",
       "      <td>3.570096</td>\n",
       "      <td>3.278251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.546212</td>\n",
       "      <td>4.342855</td>\n",
       "      <td>4.989985</td>\n",
       "      <td>1.424306</td>\n",
       "      <td>3.139483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.951667</td>\n",
       "      <td>3.874441</td>\n",
       "      <td>5.702188</td>\n",
       "      <td>2.583553</td>\n",
       "      <td>4.083078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.621914</td>\n",
       "      <td>3.661797</td>\n",
       "      <td>4.905356</td>\n",
       "      <td>2.256799</td>\n",
       "      <td>2.612209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.695660</td>\n",
       "      <td>3.161980</td>\n",
       "      <td>6.271505</td>\n",
       "      <td>2.331119</td>\n",
       "      <td>4.303026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.959672</td>\n",
       "      <td>3.044083</td>\n",
       "      <td>4.627399</td>\n",
       "      <td>1.678197</td>\n",
       "      <td>2.985087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.270678</td>\n",
       "      <td>3.793009</td>\n",
       "      <td>4.627846</td>\n",
       "      <td>1.532905</td>\n",
       "      <td>3.075767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.381561</td>\n",
       "      <td>3.632883</td>\n",
       "      <td>3.899534</td>\n",
       "      <td>3.435285</td>\n",
       "      <td>1.192768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.776171</td>\n",
       "      <td>4.249670</td>\n",
       "      <td>5.819146</td>\n",
       "      <td>2.509451</td>\n",
       "      <td>4.519527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.864812</td>\n",
       "      <td>3.938193</td>\n",
       "      <td>4.904687</td>\n",
       "      <td>1.630394</td>\n",
       "      <td>2.267505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1.642571</td>\n",
       "      <td>3.123194</td>\n",
       "      <td>3.912580</td>\n",
       "      <td>3.315629</td>\n",
       "      <td>1.713088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>2.764400</td>\n",
       "      <td>4.229572</td>\n",
       "      <td>4.391208</td>\n",
       "      <td>2.537892</td>\n",
       "      <td>2.340847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3.312710</td>\n",
       "      <td>3.077778</td>\n",
       "      <td>6.021182</td>\n",
       "      <td>2.728698</td>\n",
       "      <td>4.384051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>2.040585</td>\n",
       "      <td>3.477917</td>\n",
       "      <td>2.783791</td>\n",
       "      <td>3.052317</td>\n",
       "      <td>1.451256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2.097563</td>\n",
       "      <td>3.495819</td>\n",
       "      <td>3.513857</td>\n",
       "      <td>3.314147</td>\n",
       "      <td>1.109965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>3.691058</td>\n",
       "      <td>4.001059</td>\n",
       "      <td>5.458780</td>\n",
       "      <td>1.586138</td>\n",
       "      <td>3.513273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>4.101763</td>\n",
       "      <td>3.539642</td>\n",
       "      <td>6.740942</td>\n",
       "      <td>3.649067</td>\n",
       "      <td>5.149534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>3.509994</td>\n",
       "      <td>3.680171</td>\n",
       "      <td>5.644149</td>\n",
       "      <td>2.220111</td>\n",
       "      <td>3.758416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2.429246</td>\n",
       "      <td>3.785981</td>\n",
       "      <td>6.304337</td>\n",
       "      <td>3.949732</td>\n",
       "      <td>3.834244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2.370837</td>\n",
       "      <td>4.088295</td>\n",
       "      <td>5.810233</td>\n",
       "      <td>4.243244</td>\n",
       "      <td>3.827402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2.651309</td>\n",
       "      <td>1.689245</td>\n",
       "      <td>4.928598</td>\n",
       "      <td>2.984468</td>\n",
       "      <td>3.314615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>4.032479</td>\n",
       "      <td>4.212428</td>\n",
       "      <td>3.975635</td>\n",
       "      <td>2.063693</td>\n",
       "      <td>3.180197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>3.179418</td>\n",
       "      <td>4.169687</td>\n",
       "      <td>4.461227</td>\n",
       "      <td>3.382656</td>\n",
       "      <td>2.910121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1.131680</td>\n",
       "      <td>3.018461</td>\n",
       "      <td>5.039038</td>\n",
       "      <td>3.206119</td>\n",
       "      <td>2.381455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2.158934</td>\n",
       "      <td>3.892943</td>\n",
       "      <td>3.541837</td>\n",
       "      <td>2.814471</td>\n",
       "      <td>0.962565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>4.514340</td>\n",
       "      <td>3.018193</td>\n",
       "      <td>7.574479</td>\n",
       "      <td>5.898975</td>\n",
       "      <td>5.639965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2.766416</td>\n",
       "      <td>3.113421</td>\n",
       "      <td>4.987376</td>\n",
       "      <td>1.465733</td>\n",
       "      <td>3.192918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1.929190</td>\n",
       "      <td>2.796913</td>\n",
       "      <td>5.792578</td>\n",
       "      <td>3.407503</td>\n",
       "      <td>3.349338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2.385669</td>\n",
       "      <td>3.208718</td>\n",
       "      <td>5.468858</td>\n",
       "      <td>2.029021</td>\n",
       "      <td>3.012702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>3.253561</td>\n",
       "      <td>4.260817</td>\n",
       "      <td>4.481563</td>\n",
       "      <td>2.553776</td>\n",
       "      <td>2.839348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2.594902</td>\n",
       "      <td>4.298580</td>\n",
       "      <td>4.311682</td>\n",
       "      <td>3.021535</td>\n",
       "      <td>1.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>4.884671</td>\n",
       "      <td>4.605620</td>\n",
       "      <td>6.233610</td>\n",
       "      <td>2.841220</td>\n",
       "      <td>4.867956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>1.983697</td>\n",
       "      <td>4.012423</td>\n",
       "      <td>3.742016</td>\n",
       "      <td>3.422551</td>\n",
       "      <td>1.644174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>3.189562</td>\n",
       "      <td>3.348518</td>\n",
       "      <td>5.435705</td>\n",
       "      <td>2.383396</td>\n",
       "      <td>4.039691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3.953084</td>\n",
       "      <td>4.914456</td>\n",
       "      <td>3.774393</td>\n",
       "      <td>2.624973</td>\n",
       "      <td>2.539151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>4.184750</td>\n",
       "      <td>3.934541</td>\n",
       "      <td>6.226939</td>\n",
       "      <td>3.251412</td>\n",
       "      <td>4.740373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1.177426</td>\n",
       "      <td>3.343494</td>\n",
       "      <td>4.197447</td>\n",
       "      <td>2.651721</td>\n",
       "      <td>1.624840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2.036565</td>\n",
       "      <td>2.866627</td>\n",
       "      <td>4.083302</td>\n",
       "      <td>2.145959</td>\n",
       "      <td>1.414666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>3.094364</td>\n",
       "      <td>4.097250</td>\n",
       "      <td>3.519238</td>\n",
       "      <td>2.318110</td>\n",
       "      <td>2.225189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.705304</td>\n",
       "      <td>3.983136</td>\n",
       "      <td>4.254447</td>\n",
       "      <td>3.290210</td>\n",
       "      <td>1.358201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0    2.562476  3.056871  4.858964  1.738996  3.243453\n",
       "1    2.062636  4.098660  3.985635  3.073679  1.328311\n",
       "2    3.996071  4.051160  4.191577  2.711857  3.345838\n",
       "3    2.155004  3.878796  4.042752  3.491955  1.223825\n",
       "4    5.630604  5.795903  7.047969  6.830491  6.659752\n",
       "5    3.049418  4.183152  3.861658  2.170804  1.490791\n",
       "6    2.121420  3.854006  3.593685  3.419456  1.847884\n",
       "7    5.142601  5.815561  2.403344  4.597557  4.483896\n",
       "8    5.366437  3.263081  7.302549  5.690635  6.091053\n",
       "9    6.147373  6.307833  6.407599  4.340649  4.922305\n",
       "10   2.800901  4.170461  5.000682  2.410370  2.223356\n",
       "11   3.663134  3.845279  4.826079  2.156993  3.583853\n",
       "12   5.070799  5.062746  6.010195  3.402221  5.019032\n",
       "13   7.535633  5.351579  8.767884  7.747371  8.028075\n",
       "14   3.208017  2.354485  4.792187  2.151853  3.299707\n",
       "15   4.749667  5.623622  1.314599  4.419648  3.945181\n",
       "16   2.028604  2.657881  6.189050  4.221002  3.797792\n",
       "17   3.034162  4.167379  3.993609  1.874972  1.846403\n",
       "18   2.712309  4.062378  3.752548  4.162374  3.345230\n",
       "19   0.648980  2.679707  4.317503  2.709044  1.700699\n",
       "20   1.658737  1.889505  5.876538  3.570096  3.278251\n",
       "21   3.546212  4.342855  4.989985  1.424306  3.139483\n",
       "22   3.951667  3.874441  5.702188  2.583553  4.083078\n",
       "23   2.621914  3.661797  4.905356  2.256799  2.612209\n",
       "24   3.695660  3.161980  6.271505  2.331119  4.303026\n",
       "25   2.959672  3.044083  4.627399  1.678197  2.985087\n",
       "26   3.270678  3.793009  4.627846  1.532905  3.075767\n",
       "27   2.381561  3.632883  3.899534  3.435285  1.192768\n",
       "28   4.776171  4.249670  5.819146  2.509451  4.519527\n",
       "29   2.864812  3.938193  4.904687  1.630394  2.267505\n",
       "..        ...       ...       ...       ...       ...\n",
       "738  1.642571  3.123194  3.912580  3.315629  1.713088\n",
       "739  2.764400  4.229572  4.391208  2.537892  2.340847\n",
       "740  3.312710  3.077778  6.021182  2.728698  4.384051\n",
       "741  2.040585  3.477917  2.783791  3.052317  1.451256\n",
       "742  2.097563  3.495819  3.513857  3.314147  1.109965\n",
       "743  3.691058  4.001059  5.458780  1.586138  3.513273\n",
       "744  4.101763  3.539642  6.740942  3.649067  5.149534\n",
       "745  3.509994  3.680171  5.644149  2.220111  3.758416\n",
       "746  2.429246  3.785981  6.304337  3.949732  3.834244\n",
       "747  2.370837  4.088295  5.810233  4.243244  3.827402\n",
       "748  2.651309  1.689245  4.928598  2.984468  3.314615\n",
       "749  4.032479  4.212428  3.975635  2.063693  3.180197\n",
       "750  3.179418  4.169687  4.461227  3.382656  2.910121\n",
       "751  1.131680  3.018461  5.039038  3.206119  2.381455\n",
       "752  2.158934  3.892943  3.541837  2.814471  0.962565\n",
       "753  4.514340  3.018193  7.574479  5.898975  5.639965\n",
       "754  2.766416  3.113421  4.987376  1.465733  3.192918\n",
       "755  1.929190  2.796913  5.792578  3.407503  3.349338\n",
       "756  2.385669  3.208718  5.468858  2.029021  3.012702\n",
       "757  3.253561  4.260817  4.481563  2.553776  2.839348\n",
       "758  2.594902  4.298580  4.311682  3.021535  1.783003\n",
       "759  4.884671  4.605620  6.233610  2.841220  4.867956\n",
       "760  1.983697  4.012423  3.742016  3.422551  1.644174\n",
       "761  3.189562  3.348518  5.435705  2.383396  4.039691\n",
       "762  3.953084  4.914456  3.774393  2.624973  2.539151\n",
       "763  4.184750  3.934541  6.226939  3.251412  4.740373\n",
       "764  1.177426  3.343494  4.197447  2.651721  1.624840\n",
       "765  2.036565  2.866627  4.083302  2.145959  1.414666\n",
       "766  3.094364  4.097250  3.519238  2.318110  2.225189\n",
       "767  1.705304  3.983136  4.254447  3.290210  1.358201\n",
       "\n",
       "[768 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(k_means_1.fit_transform(scaler_df))\n",
    "#k_means_1.fit_transform(scaler_df)\n",
    "\n",
    "# now compare each record from above wih below array\n",
    "# They are assigned to the minimum distance out of 0 to 4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
